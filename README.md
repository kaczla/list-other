# Random list

This repository contains random elements from the Internet.
The purpose of this repository is to archive elements that I decided as important, and it would be nice o have quick access to them.

# List

- [Can LLMs learn from a single example?](data/llm_single_example)
  - Source: [fast.ai](https://www.fast.ai/posts/2023-09-04-learning-jumps/) (access February 2024)
- [Everything about Distributed Training and Efficient Finetuning](data/distributed_training)
  - Source: [sumanthrh.com](https://sumanthrh.com/post/distributed-and-efficient-finetuning/) (access February 2024)
- [Compressing Text into Images](data/compressing_text_into_images)
  - Source: [shkspr.mobi](https://shkspr.mobi/blog/2024/01/compressing-text-into-images/) (access February 2024)
- [LLM Visualization](data/llm_visualization)
  - Source: [bbycroft.net](https://bbycroft.net/llm) (access February 2024)
- [Mastering curl: interactive text guide](data/mastering_curl)
  - Source: [antonz.org](https://antonz.org/mastering-curl/) (access February 2024)
- [Neural Circuit Diagrams](data/neural_circuit_diagrams)
  - Source: [twitter](https://twitter.com/jxmnop/status/1757244005639766157) (access February 2024)
- [Using Language Models to (probably) Read Faster](data/read_faster_llm)
  - Source: [ahrm.github.io](https://ahrm.github.io/jekyll/update/2022/04/14/using-languge-models-to-read-faster.html) (access February 2024)
- [3D Parallelism Simple Visualization - BigScience](data/3d_parallelism_bigscience)
  - Source: [twitter](https://twitter.com/BigScienceLLM/status/1506588988278198273) (access February 2024)
- [makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch](data/moe_transformer)
  - Source: [HuggingFace blog](https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch) (access February 2024)
- [Asking 60+ LLMs a set of 20 questions](data/llmonitor)
  - Source: [benchmarks.llmonitor.com](https://benchmarks.llmonitor.com/) (access August 2023)
- [The move from a distributed microservices architecture to a monolith application helped achieve higher scale, resilience, and reduce costs](data/from_microservices_to_monolith)
  - Source: [primevideotech.com](https://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90) (access August 2023)
- [Memory Allocation](data/memory_allocation)
  - Source: [samwho.dev](https://samwho.dev/memory-allocation/) (access August 2023)
- [Visual guide of Transformer architecture](data/transformer_visualization)
  - Source: [twitter](https://twitter.com/akshay_pachaar/status/1647940492712345601) (access April 2023)
- [TCP vs. UDP: 7 Differences You Should Know](data/tcp_vs_udp)
  - Source: [twitter](https://twitter.com/alexxubyte/status/1643640904459386880) (access April 2023)
- [Vocab Size as a Multiple of 64](data/vocab_multiple_of_64)
  - Source: [twitter](https://twitter.com/karpathy/status/1621578354024677377) (access March 2023)
- [Sharding Large Models with Tensor Parallelism](data/tensor_parallel)
  - Source: [Misha Laskin blog](https://www.mishalaskin.com/posts/tensor_parallel) (access March 2023)
- [Making model initialization faster in PyTorch](data/faster_model_initialization)
  - Source [Lernapparat blog](https://lernapparat.de/faster-model-init) (access March 2023)
- [PyTorch, Gradient Accumulation, and the dreaded drop in speed](data/analysis_accelerate)
  - Source: [Zach Mueller blog](https://muellerzr.github.io/blog/gradient_accumulation.html) (access March 2023)
- [Animations and instructional videos about neural networks](data/animated_ai)
  - Source: [animatedai.github.io](https://animatedai.github.io/) (access February 2023)
- [Compare Transformer Self-Attention and Cross-Attention - Visualization](data/transformer_compare_attentions)
  - Source: [twitter](https://twitter.com/rasbt/status/1624441393182539777) and [Sebastian Raschka Blog](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html) (access February 2023)
- [3D Parallelism Simple Visualization](data/3d_parallelism)
  - Source: [twitter](https://twitter.com/rasbt/status/1625494398778892292) (access February 2023)
- [List of free ebooks](data/free_ebook)
  - Source: [lagout.org/programmation](https://doc.lagout.org/programmation/) and [goalkicker.com](https://goalkicker.com) (access February 2023)
- [Diagram of loss functions in machine learning](data/loss_functions_in_machine_learning)
  - Source: [publication](https://arxiv.org/abs/2301.05579) (access January 2023)
- [List and diagrams of Transformer models](data/transformer_list) (many diagrams/lists)
  - Source: [publication](https://arxiv.org/abs/2301.04655) (access January 2023)
- [Simple visualizations of learning rate schedulers](data/learning_rates)
  - Source: [GitHub](https://github.com/rasbt/machine-learning-notes/blob/7abac1b3dfe47b84887fcee80e5cca0e7ebf5061/learning-rates/scheduler-comparison/overview.png) (access January 2023)
- [Optimizing minGPT from 495ms to 102ms](data/optimizing_mingpt)
  - Source: [twitter](https://twitter.com/karpathy/status/1607791537978748929) (access January 2023)
- [AdamW optimizer with weight decay can archive better results on smaller datasets that other methods](data/adamw_optimizer_weight_decay)
  - Source: [publication](https://arxiv.org/abs/2201.02177) (access January 2023)
- [Nvida GPU FLOPs - image](data/nvidia_gpu_flops)
  - Source: [twitter](https://twitter.com/cHHillee/status/1613955410695708672) (access January 2023)
- [Timeline & Marketshare ob Browser Engines - image](data/browser_egines)
  - Source: [History of Web Browser Engines from 1990 until today](https://eylenburg.github.io/browser_engines.htm) (access January 2023)
